{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T04:53:09.223731Z",
     "iopub.status.busy": "2025-04-19T04:53:09.223198Z",
     "iopub.status.idle": "2025-04-19T04:58:40.583037Z",
     "shell.execute_reply": "2025-04-19T04:58:40.581855Z",
     "shell.execute_reply.started": "2025-04-19T04:53:09.223706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting open_clip_torch\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/32/f9/0458745c1d299411161ee3b6c32228a3de0be1d8497d779fd7f17a8e96aa/open_clip_torch-2.32.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.20.1+cu124)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2024.11.6)\n",
      "Collecting ftfy (from open_clip_torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ab/6e/81d47999aebc1b155f81eca4477a616a70f238a2549848c38983f3c22a82/ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.30.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.5.2)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (1.0.14)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9f/fd/713452cd72343f682b1c7b9321e23829f00b842ceaedcda96e742ea0b0b3/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ae/71/1c91302526c45ab494c23f61c7a84aa568b8c1f9d196efa5993957faf906/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/27/94/3266821f65b92b3138631e9c8e7fe1fb513804ac934485a8d05776e1dd43/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8a/6d/44ad094874c6f1b9c654f8ed939590bdc408349f137f9b98a3a23ccec411/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3a/e1/5b9089a4b2a4790dfdea8b3a006052cfecff58139d5a4e34cb1a51df8d6f/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/db/f7/97a9ea26ed4bbbfc2d470994b8b4f338ef663be97b8f677519ac195e113d/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9.0->open_clip_torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ff/ff/847841bacfbefc97a00036e0fce5a0f086b640756dc38caea5e1bb002655/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->open_clip_torch) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->open_clip_torch) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->open_clip_torch) (2024.2.0)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, open_clip_torch\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open_clip_torch-2.32.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install open_clip_torch -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-19T04:58:44.674419Z",
     "iopub.status.busy": "2025-04-19T04:58:44.674070Z",
     "iopub.status.idle": "2025-04-19T04:58:57.069200Z",
     "shell.execute_reply": "2025-04-19T04:58:57.068594Z",
     "shell.execute_reply.started": "2025-04-19T04:58:44.674384Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "import torch\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "import random\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:11:30.220839Z",
     "iopub.status.busy": "2025-04-18T17:11:30.220508Z",
     "iopub.status.idle": "2025-04-18T17:11:33.024626Z",
     "shell.execute_reply": "2025-04-18T17:11:33.023880Z",
     "shell.execute_reply.started": "2025-04-18T17:11:30.220813Z"
    }
   },
   "outputs": [],
   "source": [
    "anime_csv = '/kaggle/input/anime-recommendations-database/anime.csv'\n",
    "rating_csv = '/kaggle/input/anime-recommendations-database/rating.csv'\n",
    "\n",
    "anime_df = pd.read_csv(anime_csv)\n",
    "rating_df = pd.read_csv(rating_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing values for each column\n",
    "print(\"Missing Values Summary\")\n",
    "print(anime_df.isnull().sum())\n",
    "\n",
    "# Check the duplicated rows\n",
    "print(\"The number of duplicated rows: \", anime_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing values for each column\n",
    "print(\"Missing Values Summary\")\n",
    "print(rating_df.isnull().sum())\n",
    "\n",
    "# Check the duplicated rows\n",
    "print(\"The number of duplicated rows: \", rating_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing rating values in anime_df with the average value\n",
    "anime_df['rating'].fillna(anime_df['rating'].mean(), inplace=True)\n",
    "\n",
    "# Missing values in Genre and Type column will be replaced with \"Unknown\" \n",
    "anime_df['genre'].fillna(\"Unknown\", inplace=True)\n",
    "anime_df['type'].fillna(\"Unknown\", inplace=True)\n",
    "anime_df['episodes'] = anime_df['episodes'].replace('Unknown', 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicated row in rating_df\n",
    "rating_df.drop_duplicates(inplace=True)\n",
    "rating_df = rating_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Encode the categorical features(genre & type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Encode the Genre column ---\n",
    "\n",
    "# Split the Genre column value to a list of categories\n",
    "genre_split = anime_df['genre'].fillna(\"\").apply(lambda x: [g.strip() for g in x.split(',') if g.strip()])\n",
    "\n",
    "# Apply MultiLabelBinarizer to do multi-hot encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_encoded = pd.DataFrame(mlb.fit_transform(genre_split), columns=[f\"genre_{g}\" for g in mlb.classes_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Encode the Type column ---\n",
    "type_encoder = LabelEncoder()\n",
    "type_encoded = pd.Series(type_encoder.fit_transform(anime_df['type']), name='type_encoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Encode the name by CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Encode the Name column ---\n",
    "# Initialize the model\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "model.eval().cuda()\n",
    "\n",
    "# Convert anime name to a list\n",
    "texts = anime_df['name'].astype(str).tolist()\n",
    "\n",
    "# A list for encoding features\n",
    "all_text_features = []\n",
    "\n",
    "# Deal them with 32 batch\n",
    "batch_size = 32\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer(batch_texts).cuda()\n",
    "        features = model.encode_text(tokens)\n",
    "        features = features / features.norm(dim=1, keepdim=True)\n",
    "        # Move features to cpu to avoid of running out of memory\n",
    "        all_text_features.append(features.cpu())\n",
    "    del tokens, features\n",
    "    # Release the memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Contact all the features\n",
    "text_features_tensor = torch.cat(all_text_features, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Build a new dataframe for model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data_df = anime_df.drop(columns=['genre', 'type', 'name'])\n",
    "text_feature_df = pd.DataFrame(text_features_tensor.numpy())\n",
    "anime_data_df = pd.concat([anime_data_df, genre_encoded, text_feature_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Save the well-preprocessed data to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data_df.to_csv('anime_data.csv', index=False)\n",
    "rating_df.to_csv('ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Read data from local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T04:59:05.532424Z",
     "iopub.status.busy": "2025-04-19T04:59:05.532089Z",
     "iopub.status.idle": "2025-04-19T04:59:10.684847Z",
     "shell.execute_reply": "2025-04-19T04:59:10.684029Z",
     "shell.execute_reply.started": "2025-04-19T04:59:05.532401Z"
    }
   },
   "outputs": [],
   "source": [
    "anime_data_df = pd.read_csv('/kaggle/input/processeddata/anime_data.csv')\n",
    "rating_df = pd.read_csv('/kaggle/input/processeddata/ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model build & training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T04:59:14.010932Z",
     "iopub.status.busy": "2025-04-19T04:59:14.010142Z",
     "iopub.status.idle": "2025-04-19T04:59:16.725141Z",
     "shell.execute_reply": "2025-04-19T04:59:16.724303Z",
     "shell.execute_reply.started": "2025-04-19T04:59:14.010906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set label --- Rate >= 6 stands for Like\n",
    "rating_df['liked'] = rating_df['rating'].apply(lambda x: 1 if x >= 6 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T04:59:19.259132Z",
     "iopub.status.busy": "2025-04-19T04:59:19.258481Z",
     "iopub.status.idle": "2025-04-19T04:59:19.264615Z",
     "shell.execute_reply": "2025-04-19T04:59:19.263690Z",
     "shell.execute_reply.started": "2025-04-19T04:59:19.259108Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_generator(indexes, rating_df, anime_data_df, batch_size=128):\n",
    "    num_samples = len(indexes)\n",
    "    indexes = np.array(indexes)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_idx = indexes[i:i+batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for idx in batch_idx:\n",
    "            row = rating_df.iloc[idx]\n",
    "            anime_id = row['anime_id']\n",
    "            rating = row['rating']\n",
    "            if anime_id in anime_data_df.index:\n",
    "                features = anime_data_df.loc[anime_id].values.astype(np.float32)\n",
    "                label = 1 if rating >= 6 else 0\n",
    "                X_batch.append(features)\n",
    "                y_batch.append(label)\n",
    "        yield np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T04:59:23.142444Z",
     "iopub.status.busy": "2025-04-19T04:59:23.141916Z",
     "iopub.status.idle": "2025-04-19T04:59:23.900736Z",
     "shell.execute_reply": "2025-04-19T04:59:23.899796Z",
     "shell.execute_reply.started": "2025-04-19T04:59:23.142411Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_idx, test_idx = train_test_split(rating_df.index, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Train a SVM model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = SGDClassifier(loss=\"hinge\", max_iter=1, warm_start=True)\n",
    "\n",
    "# SVM Training\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    for X_batch, y_batch in tqdm(batch_generator(train_idx, rating_df, anime_data_df, 4096)):\n",
    "        if len(X_batch) > 0:\n",
    "            model.partial_fit(X_batch, y_batch, classes=np.array([0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all the parameters of the model\n",
    "params = model.get_params() \n",
    "\n",
    "# Get the weights and bias\n",
    "coef = model.coef_.tolist()\n",
    "intercept = model.intercept_.tolist()\n",
    "\n",
    "# Save to a dict\n",
    "model_data = {\n",
    "    \"params\": params,\n",
    "    \"coef\": coef,\n",
    "    \"intercept\": intercept\n",
    "}\n",
    "\n",
    "# Save as json\n",
    "with open('sgd_model_params.json', 'w') as f:\n",
    "    json.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the tester generator\n",
    "test_generator = batch_generator(test_idx, rating_df, anime_data_df, 4096)\n",
    "\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "# Test the model\n",
    "for X_batch, y_batch in tqdm(test_generator, desc=\"Testing Batches\", unit=\"batch\"):\n",
    "    if len(X_batch) > 0:\n",
    "        preds = model.predict(X_batch)\n",
    "        all_preds.extend(preds)\n",
    "        all_true.extend(y_batch)\n",
    "\n",
    "# Output the results of the test\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(classification_report(all_true, all_preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Refine the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T04:59:43.028273Z",
     "iopub.status.busy": "2025-04-19T04:59:43.027658Z",
     "iopub.status.idle": "2025-04-19T04:59:43.036469Z",
     "shell.execute_reply": "2025-04-19T04:59:43.035403Z",
     "shell.execute_reply.started": "2025-04-19T04:59:43.028249Z"
    }
   },
   "outputs": [],
   "source": [
    "def balanced_batch_generator(indexes, rating_df, anime_data_df, batch_size=128, neg_pos_ratio=1.0):\n",
    "    # Shuffle the indexes\n",
    "    indexes = list(indexes)\n",
    "    random.shuffle(indexes)\n",
    "    num_samples = len(indexes)\n",
    "    indexes = np.array(indexes)\n",
    "    random.shuffle(indexes)\n",
    "    num_samples = len(indexes)\n",
    "    indexes = np.array(indexes)\n",
    "\n",
    "    for i in range(0, num_samples, batch_size * 2):\n",
    "        batch_idx = indexes[i:i + batch_size * 2]\n",
    "        pos_samples = []\n",
    "        neg_samples = []\n",
    "\n",
    "        for idx in batch_idx:\n",
    "            row = rating_df.iloc[idx]\n",
    "            anime_id = row['anime_id']\n",
    "            rating = row['rating']\n",
    "            if anime_id not in anime_data_df.index:\n",
    "                continue\n",
    "\n",
    "            features = anime_data_df.loc[anime_id].values.astype(np.float32)\n",
    "            label = 1 if rating >= 6 else 0\n",
    "\n",
    "            if label == 1:\n",
    "                pos_samples.append((features, label))\n",
    "            else:\n",
    "                neg_samples.append((features, label))\n",
    "\n",
    "        # Resampling by the given ratio\n",
    "        num_pos = int(min(len(pos_samples), batch_size // (1 + neg_pos_ratio)))\n",
    "        num_neg = int(num_pos * neg_pos_ratio)\n",
    "\n",
    "        pos_samples = random.sample(pos_samples, min(num_pos, len(pos_samples)))\n",
    "        neg_samples = random.choices(neg_samples, k=min(num_neg, len(neg_samples)))\n",
    "\n",
    "        # Combine and Shuffle\n",
    "        batch = pos_samples + neg_samples\n",
    "        random.shuffle(batch)\n",
    "        X_batch, y_batch = zip(*batch)\n",
    "\n",
    "        yield np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Balance Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T07:33:37.116989Z",
     "iopub.status.busy": "2025-04-19T07:33:37.116670Z",
     "iopub.status.idle": "2025-04-19T12:09:32.537958Z",
     "shell.execute_reply": "2025-04-19T12:09:32.537200Z",
     "shell.execute_reply.started": "2025-04-19T07:33:37.116970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 687it [27:30,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 687it [27:35,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 687it [27:26,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 687it [27:24,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 687it [27:35,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 687it [27:41,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 687it [27:38,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 687it [27:45,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 687it [27:42,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 687it [27:35,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = SGDClassifier(\n",
    "    loss='log_loss',\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    tol=1e-3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Start the training\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    train_generator = balanced_batch_generator(\n",
    "        train_idx, \n",
    "        rating_df, \n",
    "        anime_data_df,\n",
    "        batch_size=4096,\n",
    "        neg_pos_ratio=2.0\n",
    "    )\n",
    "    for X_batch, y_batch in tqdm(train_generator, desc=\"Training\"):\n",
    "        model.partial_fit(X_batch, y_batch, classes=np.array([0, 1]))\n",
    "    # Save the model\n",
    "    joblib.dump(model, f'animeSVCBoost_{epoch+1}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:46:04.793277Z",
     "iopub.status.busy": "2025-04-19T12:46:04.792361Z",
     "iopub.status.idle": "2025-04-19T12:54:26.616799Z",
     "shell.execute_reply": "2025-04-19T12:54:26.615756Z",
     "shell.execute_reply.started": "2025-04-19T12:46:04.793247Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Batches: 382batch [08:19,  1.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2441    0.3291    0.2803    281430\n",
      "           1     0.7474    0.6608    0.7014    845415\n",
      "\n",
      "    accuracy                         0.5779   1126845\n",
      "   macro avg     0.4957    0.4949    0.4908   1126845\n",
      "weighted avg     0.6217    0.5779    0.5962   1126845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the tester generator\n",
    "test_generator = batch_generator(test_idx, rating_df, anime_data_df, 4096)\n",
    "\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "# Test the model\n",
    "for X_batch, y_batch in tqdm(test_generator, desc=\"Testing Batches\", unit=\"batch\"):\n",
    "    if len(X_batch) > 0:\n",
    "        preds = model.predict(X_batch)\n",
    "        all_preds.extend(preds)\n",
    "        all_true.extend(y_batch)\n",
    "\n",
    "# Output the results of the test\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(classification_report(all_true, all_preds, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 571,
     "sourceId": 1094,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7181180,
     "sourceId": 11460534,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 308228,
     "modelInstanceId": 287428,
     "sourceId": 343704,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 308377,
     "modelInstanceId": 287578,
     "sourceId": 343868,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
